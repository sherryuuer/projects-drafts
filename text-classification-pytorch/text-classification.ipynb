{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import qc, stopwords\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from scipy.sparse import csr_matrix\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "\n",
    "import transformers\n",
    "from transformers import MobileBertTokenizer, MobileBertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download question classification dataset and explore\n",
    "\n",
    "The question classification dataset contains questions labeled into 50 classes, which can be categorized into six main categories. \n",
    "\n",
    "- ABBR: Denotes abbreviations\n",
    "- ENTY: Stands for entities\n",
    "- DESC: Denotes descriptions and abstract concepts\n",
    "- HUM: Denotes human beings\n",
    "- LOC: Denotes locations\n",
    "- NUM: Stands for numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Question Classification dataset\n",
    "nltk.download('qc')\n",
    "train_tuples = qc.tuples(\"train.txt\")\n",
    "test_tuples = qc.tuples(\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_tuples), len(test_tuples)\n",
    "# (5452, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tuples[0]\n",
    "# ('DESC:manner', 'How did serfdom develop in and then leave Russia ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data into DataFrame\n",
    "train_df = pd.DataFrame(train_tuples, columns=['full_label', 'text'])\n",
    "test_df = pd.DataFrame(test_tuples, columns=['full_label', 'text'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split label into main category and the granular category\n",
    "train_df[['main_cat', 'gran_cat']] = train_df['full_label'].str.split(':', expand=True)\n",
    "test_df[['main_cat', 'gran_cat']] = test_df['full_label'].str.split(':', expand=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many categories do they have?\n",
    "print(\"***********train***********\")\n",
    "print(f'no of unique classes: {len(train_df[\"full_label\"].unique())}')\n",
    "print(f'no of  main classes: {len(train_df[\"main_cat\"].unique())}')\n",
    "print(f'no of granular  classes: {len(train_df[\"gran_cat\"].unique())}')\n",
    "print(\"***********test***********\")\n",
    "print(f'no of unique classes: {len(test_df[\"full_label\"].unique())}')\n",
    "print(f'no of  main classes: {len(test_df[\"main_cat\"].unique())}')\n",
    "print(f'no of granular  classes: {len(test_df[\"gran_cat\"].unique())}')\n",
    "\n",
    "# See the distribution of the examples.\n",
    "print('***********train***********')\n",
    "print(train_df[\"main_cat\"].value_counts())\n",
    "print('***********test***********')\n",
    "print(test_df[\"main_cat\"].value_counts())\n",
    "\n",
    "# Are all the training labels present in the test set and vice versa?\n",
    "all_unique_values = set(train_df[\"full_label\"].unique()) | set(test_df[\"full_label\"].unique())\n",
    "len(all_unique_values)\n",
    "\n",
    "# ***********train***********\n",
    "# no of unique classes: 50\n",
    "# no of  main classes: 6\n",
    "# no of granular  classes: 47\n",
    "# ***********test***********\n",
    "# no of unique classes: 42\n",
    "# no of  main classes: 6\n",
    "# no of granular  classes: 39\n",
    "# ***********train***********\n",
    "# main_cat\n",
    "# ENTY    1250\n",
    "# HUM     1223\n",
    "# DESC    1162\n",
    "# NUM      896\n",
    "# LOC      835\n",
    "# ABBR      86\n",
    "# Name: count, dtype: int64\n",
    "# ***********test***********\n",
    "# main_cat\n",
    "# DESC    138\n",
    "# NUM     113\n",
    "# ENTY     94\n",
    "# LOC      81\n",
    "# HUM      65\n",
    "# ABBR      9\n",
    "# Name: count, dtype: int64\n",
    "# 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process text\n",
    "\n",
    "- make copy\n",
    "- convert text to lowercase\n",
    "- remove punctuation\n",
    "- remove stop words\n",
    "- label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy of dataframes\n",
    "train_orig = train_df.copy()\n",
    "test_orig = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "train_df['text'] = train_df['text'].str.lower()\n",
    "test_df['text'] = test_df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "train_df['text'] = train_df['text'].str.replace(f'[{string.punctuation}]', '')\n",
    "test_df['text'] = test_df['text'].str.replace(f'[{string.punctuation}]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)\n",
    "print(f'num of stop words: {len(stop_words)}')\n",
    "\n",
    "# ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "# num of stop words: 179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = [\"which\", \"who\", \"why\", \"how\", \"what\", \"when\", \"where\", \"whom\"]\n",
    "stop_words = [word for word in stop_words if word not in remove_list]\n",
    "print(f'num of stop words: {len(stop_words)}')\n",
    "\n",
    "# num of stop words: 171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that takes text and a stop word list and remove the stopwords\n",
    "def remove_stop_words(text, stop_words):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to datasets\n",
    "train_df['text'] = train_df['text'].apply(lambda x: remove_stop_words(x, stop_words))\n",
    "test_df['text'] = test_df['text'].apply(lambda x: remove_stop_words(x, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of labelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fit label\n",
    "le.fit(train_orig['main_cat'])\n",
    "\n",
    "# get the mapping\n",
    "label_mapping = {label: encoded_label for label, encoded_label in zip(le.classes_, le.transform(le.classes_))}\n",
    "print(label_mapping)\n",
    "\n",
    "# {'ABBR': 0, 'DESC': 1, 'ENTY': 2, 'HUM': 3, 'LOC': 4, 'NUM': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use le.transform to encode the labels\n",
    "train_df['main_cat'] = le.transform(train_df['main_cat'])\n",
    "test_df['main_cat'] = le.transform(test_df['main_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()\n",
    "\n",
    "# \tfull_label\ttext\tmain_cat\tgran_cat\n",
    "# 0\tDESC:manner\thow serfdom develop leave russia ?\t1\tmanner\n",
    "# 1\tENTY:cremat\twhat films featured character popeye doyle ?\t2\tcremat\n",
    "# 2\tDESC:manner\thow find list celebrities ' real names ?\t1\tmanner\n",
    "# 3\tENTY:animal\twhat fowl grabs spotlight chinese year monkey ?\t2\tanimal\n",
    "# 4\tABBR:exp\twhat full form .com ?\t0\texp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the features and labels\n",
    "X = train_df['text']\n",
    "y = train_df['main_cat']\n",
    "X_test = test_df['text']\n",
    "y_test = test_df['main_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size = 0.15,\n",
    "    random_state = 42,\n",
    "    stratify = y # adjust percentage by y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of X_valid: {X_valid.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "\n",
    "total_size = len(X_train)+len(X_valid)+len(X_test)\n",
    "print(f'total dataset size: {total_size}')\n",
    "print(f'train %: {len(X_train)/total_size*100}')\n",
    "print(f'valid %: {len(X_valid)/total_size*100}')\n",
    "print(f'test %: {len(X_test)/total_size*100}')\n",
    "\n",
    "# Shape of X_train: (4634,)\n",
    "# Shape of X_valid: (818,)\n",
    "# Shape of X_test: (500,)\n",
    "# total dataset size: 5952\n",
    "# train %: 77.85618279569893\n",
    "# valid %: 13.743279569892472\n",
    "# test %: 8.400537634408602"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features (BoW)\n",
    "\n",
    "BoW模型是\"Bag of Words\"（词袋模型）的缩写，是自然语言处理（NLP）中常用的一种表示文本的方法。在这个模型中，文本被看作是一个由单词组成的集合，忽略了单词出现的顺序和语法结构，只关注单词的频率信息。具体来说，BoW模型将文本表示为一个由单词构成的向量，向量的每个维度代表一个单词，在这个维度上的值代表了对应单词在文本中出现的次数或者其他统计信息（比如TF-IDF值）。\n",
    "\n",
    "BoW模型简单易懂，适用于许多NLP任务，比如文本分类、情感分析、信息检索等。然而，由于忽略了单词的顺序和语义信息，BoW模型在处理含有语义复杂性的文本时可能会失去一些重要的信息。\n",
    "\n",
    "n-grams是一种用于从文本中提取特征的方法，它将文本分成长度为n的连续单词序列。n-grams可用于语言建模、文本分类、信息检索等自然语言处理任务中。\n",
    "\n",
    "常见的n-grams包括：\n",
    "\n",
    "1. **Unigrams (n=1)**：单个单词组成的序列。\n",
    "2. **Bigrams (n=2)**：由两个相邻单词组成的序列。\n",
    "3. **Trigrams (n=3)**：由三个相邻单词组成的序列。\n",
    "4. **4-grams, 5-grams, ...**：依此类推，由n个相邻单词组成的序列。\n",
    "\n",
    "例如，对于句子：\"The cat sat on the mat\"，该句子的bigrams为：\n",
    "\n",
    "- \"The cat\"\n",
    "- \"cat sat\"\n",
    "- \"sat on\"\n",
    "- \"on the\"\n",
    "- \"the mat\"\n",
    "\n",
    "n-grams可以捕捉到文本中更多的局部信息，相较于词袋模型（Bag of Words），它保留了一定的顺序信息。在文本处理任务中，n-grams经常与词袋模型一起使用，作为文本特征的一部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init Countvectorizer with 1- and 2- grams\n",
    "count_vect = CountVectorizer(ngram_range=(1, 2), max_features=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the CountVectorizer\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "# transform on valid and test data\n",
    "X_valid_counts = count_vect.transform(X_valid)\n",
    "X_test_counts = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_counts.shape)\n",
    "# Calculate the frequencies\n",
    "word_frequencies = np.array(X_train_counts.sum(axis=0))[0]\n",
    "print(word_frequencies.shape)\n",
    "# Get the indexes that would sort the word frequencies\n",
    "sorted_indexes = np.argsort(word_frequencies)\n",
    "print(sorted_indexes.shape)\n",
    "# Get the vocabulary words corresponding to the indexes\n",
    "vocabulary_words = np.array(count_vect.get_feature_names_out())\n",
    "print(vocabulary_words.shape)\n",
    "# Get the top and bottom frequent words\n",
    "top_10_tokens = vocabulary_words[sorted_indexes[-10:]][::-1]\n",
    "bottom_10_tokens = vocabulary_words[sorted_indexes[:10]]\n",
    "\n",
    "print(\"Top 10 frequent tokens:\")\n",
    "print(top_10_tokens)\n",
    "\n",
    "print(\"\\nBottom 10 frequent tokens:\")\n",
    "print(bottom_10_tokens)\n",
    "\n",
    "# (4634, 8000)\n",
    "# (8000,)\n",
    "# (8000,)\n",
    "# (8000,)\n",
    "# Top 10 frequent tokens:\n",
    "# ['what' 'how' 'who' 'many' 'name' 'how many' 'where' 'first' 'when'\n",
    "#  'world']\n",
    "\n",
    "# Bottom 10 frequent tokens:\n",
    "# ['peugeot' 'poing french' 'poing' 'poets society' 'poets' 'poetic meter'\n",
    "#  'poetic' 'poet penned' 'poet co' 'poems made']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features (TF-IDF)\n",
    "\n",
    "由于ngrams方法的限制，也就是出现频率越高，它就越重要，TF-IDF则可以解决这个问题。\n",
    "\n",
    "* Term: A term refers to an item in your vocabulary. For instance, in the above example, “films” is a term.\n",
    "* Document: In this context, the entire sentence “Which films featured the character Popeye Doyle?” is considered a document.\n",
    "* Collection: The collection is a group of documents, such as your training dataset.\n",
    "\n",
    "TF (term frequency) measures how many times a term appears in a document, divided by the total number of terms in the collection. IDF (inverse document frequency) assesses how many documents contain a term relative to the total number of documents. Rare words appearing in only a few documents have higher IDF scores, whereas common words like “what” receive lower scores.\n",
    "\n",
    "TF是一个单词在一个文档中的次数/所有文档中的次数，IDF包含该词的文档数量/文档数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(ngram_range=(1, 2), max_features=8000)\n",
    "X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "X_valid_tfidf = tfidf_vect.transform(X_valid)\n",
    "X_test_tfidf = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model solution - logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "def get_accuracy(clf, X_data_split, y_data_split, split_name):\n",
    "    y_pred = clf.predict(X_data_split)\n",
    "    acc_score = accuracy_score(y_data_split, y_pred)\n",
    "    print(f'Accuracy on {split_name} : {acc_score}')\n",
    "    return acc_score\n",
    "\n",
    "# evaluate the model\n",
    "get_accuracy(clf, X_train_tfidf, y_train, 'train')\n",
    "get_accuracy(clf, X_valid_tfidf, y_valid, 'valid')\n",
    "get_accuracy(clf, X_test_tfidf, y_test, 'test')\n",
    "\n",
    "# Accuracy on train : 0.9596460940871817\n",
    "# Accuracy on valid : 0.8227383863080685\n",
    "# Accuracy on test : 0.836"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one way is just change the optimizer and regularizer\n",
    "clf = LogisticRegression(\n",
    "    random_state = 42, \n",
    "    solver = 'saga',\n",
    "    penalty = 'elasticnet',\n",
    "    l1_ratio = 0.0025,\n",
    "    max_iter = 500\n",
    ")\n",
    "\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "get_accuracy(clf, X_train_tfidf, y_train, 'train')\n",
    "get_accuracy(clf, X_valid_tfidf, y_valid, 'valid')\n",
    "get_accuracy(clf, X_test_tfidf, y_test, 'test')\n",
    "\n",
    "# Accuracy on train : 0.9594302977988779\n",
    "# Accuracy on valid : 0.8227383863080685\n",
    "# Accuracy on test : 0.836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search CV\n",
    "model = LogisticRegression()\n",
    "\n",
    "# define hyperparameter grid\n",
    "param_dist = {\n",
    "    'C': uniform(loc=0, scale=4),  # Range for regularization strength (log-scale)\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], # choice of optimizing algorithm\n",
    "    'max_iter': np.arange(100, 500, 100),  # Range for maximum iterations\n",
    "}\n",
    "\n",
    "# create RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions = param_dist,\n",
    "    n_iter = 15,\n",
    "    scoring = 'accuracy',\n",
    "    cv = 5,\n",
    "    random_state = 42,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# fit the randomized search to data\n",
    "random_search.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a new model\n",
    "# get the best hyperparameters and corr esponding score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print('Best Hyperparameters:', best_params)\n",
    "print('Best Accuracy Score', best_score)\n",
    "\n",
    "# fit the model on train data\n",
    "best_model = LogisticRegression(**best_params)\n",
    "best_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Best Hyperparameters: {'C': 3.7542108360630007, 'max_iter': 200, 'solver': 'sag'}\n",
    "# Best Accuracy Score 0.820242497105086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on test data\n",
    "get_accuracy(best_model, X_test_tfidf, y_test, 'test')\n",
    "\n",
    "# Accuracy on test : 0.848\n",
    "# get a better score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = XGBClassifier()\n",
    "bst.fit(X_train_tfidf, y_train)\n",
    "\n",
    "get_accuracy(bst, X_train_tfidf, y_train, 'train')\n",
    "get_accuracy(bst, X_valid_tfidf, y_valid, 'valid')\n",
    "get_accuracy(bst, X_test_tfidf, y_test, 'test')\n",
    "\n",
    "# Accuracy on train : 0.9115235217954252\n",
    "# Accuracy on valid : 0.7701711491442543\n",
    "# Accuracy on test : 0.808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on cunfusion matrix\n",
    "y_pred = bst.predict(X_test_tfidf)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=bst.classes_)\n",
    "\n",
    "# display\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# compute precision, recall and f1 score\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(precision, recall, f1)\n",
    "\n",
    "# (0.8611752545511348, 0.7591300972695163, 0.7922182374995442)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network (Linear) solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a neural network class\n",
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(8000, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, 6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom dataset class\n",
    "class TfidfDataset(Dataset):\n",
    "    def __init__(self, tfidf_vectors, labels, transform=None, target_transform=None):\n",
    "        self.labels = torch.tensor(labels.values)\n",
    "        self.feature_vectors = torch.tensor(csr_matrix.todense(tfidf_vectors)).float()\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature_vector = self.feature_vectors[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            feature_vector = self.transform(feature_vector)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return feature_vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate TfidfDataset objects\n",
    "train_dataset = TfidfDataset(X_train_tfidf, y_train)\n",
    "valid_dataset = TfidfDataset(X_valid_tfidf, y_valid)\n",
    "test_dataset = TfidfDataset(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size\n",
    "batch_size = 64\n",
    "# instantiate dataloader objects\n",
    "tfidf_train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "tfidf_valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "tfidf_test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model, optimizer, loss function, and device\n",
    "net = ClassificationNet()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.002)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(device)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def train_nn(\n",
    "    net,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    n_epochs = 3\n",
    "):\n",
    "    len_train_dataloader = len(train_dataloader)\n",
    "    len_valid_dataloader = len(valid_dataloader)\n",
    "    train_losses, valid_losses = [], []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        total_train_loss = 0.0\n",
    "        net.train()\n",
    "\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            total_valid_loss = 0.0\n",
    "\n",
    "            for data in valid_dataloader:\n",
    "                valid_inputs, valid_labels = data\n",
    "                valid_inputs = valid_inputs.to(device)\n",
    "                valid_labels = valid_labels.to(device)\n",
    "\n",
    "                outputs = net(valid_inputs)\n",
    "\n",
    "                total_valid_loss += criterion(outputs, valid_labels).item()\n",
    "        \n",
    "        train_losses.append(total_train_loss/len_train_dataloader)\n",
    "        valid_losses.append(total_valid_loss/len_valid_dataloader)\n",
    "\n",
    "    print('Finished Training')\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curve function\n",
    "def plot_learning_curve(train_losses, valid_losses):\n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(valid_losses, label='Validation loss')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate function\n",
    "def evaluate_classnet(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            predictions.extend(predicted.tolist())\n",
    "    accuracy = 100 * correct // total\n",
    "    precision = precision_score(y_test, predictions, average='macro')\n",
    "    recall = recall_score(y_test, predictions, average='macro')\n",
    "    f1 = f1_score(y_test, predictions, average='macro')\n",
    "    print(f'Accuracy: {accuracy} %')\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    return predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 4\n",
    "train_losses, valid_losses = train_nn(\n",
    "    net,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    tfidf_train_dataloader,\n",
    "    tfidf_valid_dataloader,\n",
    "    n_epochs = n_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, accuracy = evaluate_classnet(net, tfidf_test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings (GloVe) + LSTM solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings into a dictionary\n",
    "glove_embed_dict = {}\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "with open('/glove6B/glove.6B.200d.txt','r') as f:\n",
    "    for index, line in enumerate(f):\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:],'float32')\n",
    "        glove_embed_dict[word] = vector\n",
    "        index_to_word[index] = word\n",
    "        word_to_index[word] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pad and unk tokens to the dict\n",
    "glove_embed_dict['<unk>'] = np.random.rand(200)\n",
    "glove_embed_dict['<pad>'] = np.zeros(200)\n",
    "index = len(glove_embed_dict)+1\n",
    "word_to_index['<unk>'] = index\n",
    "index_to_word[index ] = '<unk>'\n",
    "index +=1\n",
    "word_to_index['<pad>'] = index\n",
    "index_to_word[index] = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average sequence length\n",
    "total_seq_len = 0\n",
    "max_seq_len = 0\n",
    "for line in train_df['text']:\n",
    "    seq_len = len(line.split(' '))\n",
    "    total_seq_len += seq_len\n",
    "    max_seq_len = max(max_seq_len, seq_len)\n",
    "\n",
    "avg_seq_len = total_seq_len/len(train_df['text'])\n",
    "print(f'Average seq len: {avg_seq_len}')\n",
    "print(f'Max seq len: {max_seq_len}')\n",
    "\n",
    "# Average seq len: 7.090975788701394\n",
    "# Max seq len: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the GloveDataset\n",
    "class GloveDataset(Dataset):\n",
    "    def __init__(self, text, labels, word_to_index, index_to_word, glove_embed_dict, max_seq_len=20):\n",
    "        self.labels = torch.tensor(labels.values)\n",
    "        self.glove_embed_dict = glove_embed_dict\n",
    "        self.word_to_index = word_to_index\n",
    "        self.index_to_word = index_to_word\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.index_seq = []\n",
    "        for line in text:\n",
    "            indices = [self.word_to_index.get(word, self.word_to_index.get('<unk>')) for word in line.split()]\n",
    "            pad_length = self.max_seq_len - len(indices)\n",
    "            indices = indices[:self.max_seq_len] + [self.word_to_index.get('<pad>')] * pad_length\n",
    "            self.index_seq.append(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indices = self.index_seq[idx]\n",
    "        label = self.labels[idx]\n",
    "        words = [self.index_to_word[i] for i in indices]\n",
    "        embeddings = torch.tensor([self.glove_embed_dict[word] for word in words], dtype=torch.float)\n",
    "        return embeddings, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define GloveClassifier\n",
    "class GloveClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(GloveClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.linear_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        out = self.linear_layer(hn[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model and data config\n",
    "input_dim = 200\n",
    "hidden_dim = 128\n",
    "output_dim = 6\n",
    "num_layers = 2 \n",
    "batch_size = 16\n",
    "learning_rate = 0.002\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate dataset and dataloader\n",
    "train_dataset = GloveDataset(X_train, y_train, word_to_index, index_to_word, glove_embed_dict)\n",
    "valid_dataset = GloveDataset(X_valid, y_valid, word_to_index, index_to_word, glove_embed_dict)\n",
    "test_dataset = GloveDataset(X_test, y_test, word_to_index, index_to_word, glove_embed_dict)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate neural netword\n",
    "model = GloveClassifier(input_dim, hidden_dim, output_dim, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "train_losses, valid_losses = train_nn(\n",
    "    model, \n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    n_epochs = n_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learning curve and evaluate the model\n",
    "plot_learning_curve(train_losses, valid_losses) # this plot is very well\n",
    "predictions, accuracy = evaluate_classnet(model, test_dataloader) \n",
    "\n",
    "# Accuracy: 85 %\n",
    "# Precision: 0.7231365957686823\n",
    "# Recall: 0.72528989139192\n",
    "# F1 Score: 0.7212330021413701"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Language Models solution \n",
    "\n",
    "GloVe and Word2vec可以处理语义但是不擅长处理上下文，这里尝试使用MobileBERT，一个bert的轻量版。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model and config\n",
    "max_len = 64\n",
    "batch_size = 32\n",
    "n_epochs = 3\n",
    "learning_rate = 1e-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instaniate tokenizer\n",
    "tokenizer = MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement custom dataset\n",
    "class MobileBertDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts.iloc[index]\n",
    "        text = \" \".join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.labels.iloc[index], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement model\n",
    "class MobileBertClassNet(torch.nn.Module):\n",
    "    def __init__(self, n_classes=6):\n",
    "        super(MobileBertClassNet, self).__init__()\n",
    "        self.l1 = MobileBertModel.from_pretrained(\"google/mobilebert-uncased\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(512, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooled_output = hidden_state[:, 0]\n",
    "        x = self.fc1(self.dropout(pooled_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mobilebert(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        total_size = 0\n",
    "        correct_pred = 0\n",
    "        predictions = []\n",
    "        for data in dataloader:\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            labels = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask)\n",
    "            total_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1) # (value, index)\n",
    "            total_size += labels.size(0)\n",
    "            correct_pred += (predicted == labels).sum().item()\n",
    "            predictions.extend(predicted.tolist())\n",
    "        accuracy = 100 * correct_pred // total_size\n",
    "        loss = total_loss/len(dataloader)\n",
    "        print(f'Accuracy : {accuracy} %\\tLoss: {loss:.4f}')\n",
    "        return  {'predictions' :predictions, 'accuracy': accuracy, 'loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement train function\n",
    "def train_mobilebert(model, criterion, optimizer, train_dataloader, valid_dataloader, n_epochs):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    len_train_dataloader = len(train_dataloader)\n",
    "    len_valid_dataloader = len(valid_dataloader)\n",
    "    for epoch in range(n_epochs):  #loop over the dataset\n",
    "        total_train_loss = 0.0\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            labels = data['targets'].to(device, dtype = torch.long)\n",
    "            optimizer.zero_grad() # zero the parameter gradients\n",
    "            outputs = model(ids, mask) # forward + backward + optimize\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        valid_loss = evaluate_mobilebert(model, valid_dataloader)['loss']\n",
    "        train_losses.append(total_train_loss/len_train_dataloader)\n",
    "        valid_losses.append(valid_loss)\n",
    "    return train_losses, valid_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X = train_orig['text']\n",
    "y = train_df['main_cat']\n",
    "X_test = test_orig['text']\n",
    "y_test = test_df['main_cat']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=1600, test_size=160, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instaniate dataset and dataloader\n",
    "train_dataset = MobileBertDataset(X_train, y_train, tokenizer, max_len)\n",
    "valid_dataset = MobileBertDataset(X_valid, y_valid, tokenizer, max_len)\n",
    "test_dataset = MobileBertDataset(X_test, y_test, tokenizer, max_len)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = MobileBertClassNet()\n",
    "model.to(device)\n",
    "\n",
    "# MobileBertClassNet(\n",
    "#   (l1): MobileBertModel(\n",
    "#     (embeddings): MobileBertEmbeddings(\n",
    "#       (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
    "#       (position_embeddings): Embedding(512, 512)\n",
    "#       (token_type_embeddings): Embedding(2, 512)\n",
    "#       (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
    "#       (LayerNorm): NoNorm()\n",
    "#       (dropout): Dropout(p=0.0, inplace=False)\n",
    "#     )\n",
    "#     (encoder): MobileBertEncoder(\n",
    "#       (layer): ModuleList(\n",
    "#         (0-23): 24 x MobileBertLayer(\n",
    "#           (attention): MobileBertAttention(\n",
    "#             (self): MobileBertSelfAttention(\n",
    "#               (query): Linear(in_features=128, out_features=128, bias=True)\n",
    "#               (key): Linear(in_features=128, out_features=128, bias=True)\n",
    "#               (value): Linear(in_features=512, out_features=128, bias=True)\n",
    "#               (dropout): Dropout(p=0.1, inplace=False)\n",
    "#             )\n",
    "#             (output): MobileBertSelfOutput(\n",
    "#               (dense): Linear(in_features=128, out_features=128, bias=True)\n",
    "#               (LayerNorm): NoNorm()\n",
    "#             )\n",
    "#           )\n",
    "# ...\n",
    "#     (pooler): MobileBertPooler()\n",
    "#   )\n",
    "#   (dropout): Dropout(p=0.3, inplace=False)\n",
    "#   (fc1): Linear(in_features=512, out_features=6, bias=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the layer of the model\n",
    "for param in model.l1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the name of trainable parameter\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "\n",
    "# fc1.weight\n",
    "# fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "train_losses, valid_losses = train_mobilebert(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    n_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learning curve\n",
    "plot_learning_curve(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate res on test data\n",
    "results = evaluate_mobilebert(model, test_dataloader)\n",
    "\n",
    "# Accuracy : 27 %\tLoss: 863967.1914"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Imbalanced Data\n",
    "\n",
    "Data imbalance in classification, where certain classes are underrepresented, can impair model performance. The dataset has this issue. To counteract it, you can follow the methods below:\n",
    "\n",
    "Generate synthetic data: Use techniques like SMOTE or advanced generative AI for new minority class samples.\n",
    "\n",
    "Oversample the minority class: Increase minority class representation by replicating its samples.\n",
    "\n",
    "Undersample the majority class: Reduce majority class samples to balance distribution.\n",
    "\n",
    "Adjust loss function weights: Increase penalties for misclassifying minority classes to focus model learning.\n",
    "\n",
    "Apply transfer learning: Start with models pre-trained on diverse datasets for better initial learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print class distribution\n",
    "print(y_train.value_counts()/len(y_train))\n",
    "print(y_test.value_counts()/len(y_test))\n",
    "\n",
    "# main_cat\n",
    "# 2    0.229375\n",
    "# 3    0.224375\n",
    "# 1    0.213125\n",
    "# 5    0.164375\n",
    "# 4    0.153125\n",
    "# 0    0.015625\n",
    "# Name: count, dtype: float64\n",
    "# main_cat\n",
    "# 1    0.276\n",
    "# 5    0.226\n",
    "# 2    0.188\n",
    "# 4    0.162\n",
    "# 3    0.130\n",
    "# 0    0.018\n",
    "# Name: count, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement get class weight\n",
    "def get_class_weight(y_split):\n",
    "    class_list = np.unique(y_split)\n",
    "    class_weight_value = compute_class_weight(class_weight='balanced', classes=class_list, y=y_split)\n",
    "    weight_dict = {}\n",
    "    weight_list = []\n",
    "    for i in range(len(class_list)):\n",
    "        weight_dict[class_list[i]] = class_weight_value[i]\n",
    "        weight_list.append(class_weight_value[i])\n",
    "    return weight_dict, weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class weight tensor\n",
    "weight_dict, weight_list = get_class_weight(y_train)\n",
    "class_weights = torch.tensor(weight_list, dtype=torch.float32)\n",
    "class_weights = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain tfidf\n",
    "net = ClassificationNet()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.002)\n",
    "net.to(device)\n",
    "train_losses, valid_losses = train_nn(\n",
    "    net, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    tfidf_train_dataloader,\n",
    "    tfidf_valid_dataloader, \n",
    "    n_epochs = n_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, accuracy = evaluate_classnet(net, tfdif_test_dataloader)  \n",
    "\n",
    "# Accuracy: 83 %\n",
    "# Precision: 0.8287213357331736\n",
    "# Recall: 0.8267149068345564\n",
    "# F1 Score: 0.8259239241514092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/usercode/tfidf_model.pt\"\n",
    "torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = ClassificationNet()\n",
    "loaded_model.load_state_dict(torch.load(path))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
